---
title: "Analysis Data - Single Days - DEF"
author: "Dafne Zorzetto"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(
	fig.align = "center",
	warning = FALSE,
	comment = NA,
	dev = "png",
	dpi = 150
)
```

Import libraries

```{r message=FALSE, warning=FALSE}
library(arrow)
library(readr)
library(lubridate)
library(dplyr)
library(readxl)
library(sf)
library(tidyr)
library(raster)
library(xtable)
library(maps)
library(WeightIt) 
library(cobalt) 
library(optmatch)
library(MatchIt) 
library(RColorBrewer)
library(corrplot)
```

# Merging datasets

Upload data

```{r upload_data, eval=FALSE, message=FALSE, warning=FALSE}
setwd("/Users/dafnezorzetto/Documents/GitHub/CausalFA/data")

# import chemical species dataset
CSN_concentration <- read_csv("Interpolated_CSN_IMPROVE/CSN_concentration_AQS.PM_PMF_C-sub_2024.03.csv")
IMPROVE_interpulation <- read_csv("Interpolated_CSN_IMPROVE/IMPROVE_interpulation_random-forest_2023.csv")

# upload positions information
IMPROVE_CSN_long_lat <- read_excel("Interpolated_CSN_IMPROVE/IMPROVE_CSN_long_lat.xlsx")

# load smokePM predictions on smoke days
preds = readRDS("wildfire_smoke/smokePM2pt5_predictions_daily_10km_20060101-20201231.rds")
# Load 10 km grid
grid_10km = read_sf("./wildfire_smoke/10km_grid_wgs84.shp")

# weather information
weather_2024 <- read_parquet("meteorology__gridmet__zcta_daily__2014.parquet")
GEOINFO_ZCTA <- read_csv("GEOINFO2023.GEOINFO_2025-02/GEOINFO2023.GEOINFO-Data.csv", skip = 1)
GEOINFO_ZCTA <- GEOINFO_ZCTA[,c(2,7,8)]
colnames(GEOINFO_ZCTA) <- c("id_ZCTA","Latitude","Longitude")

# coordinates
coords_6 <- read.csv("~/Documents/GitHub/CausalFA/data/weather/coords_6.csv")

# census data: 2014
# lat and long from june dataset
load("~/Documents/GitHub/CausalFA/data/census_data.RData")
#colnames(my_points)[-1]<-c("count population","housing units","gender","")
my_points$B00001_001[is.na(my_points$B00001_001)]<-median(my_points$B00001_001, na.rm = TRUE)
my_points$B20004_001[is.na(my_points$B20004_001)]<-median(my_points$B20004_001, na.rm = TRUE)
```

Upload model estimation functions

```{r upload_model, message=FALSE, warning=FALSE}
setwd("/Users/dafnezorzetto/Documents/GitHub/CausalFA/data")

# model's Gibbs sampler
source("../src/10_causal_fa_Lt_stand_mixfree_reg.R")
source("../src/2_causal_fa_Lt_X.R")
source("../src/bart_bcf.R")
```

General functions to merge datasets for the same time period

```{r message=FALSE, warning=FALSE}
merge_data_days <- function(year, months){
  
  ## --- CSN data set ---
  # select year
  CSN_year <- CSN_concentration[year(ymd(CSN_concentration$Date)) == year, ]
  # select month(s)
  CSN_y_m <- CSN_year[month(ymd(CSN_year$Date)) %in% months, ]
  unique_date_CSN <-unique(CSN_y_m$Date)
  
  ## --- IMPROVE data set ---
  # select year
  IMPROVE_year <- IMPROVE_interpulation[year(ymd(IMPROVE_interpulation$Date)) == year, ]
  # select month(s)
  IMPROVE_y_m <- IMPROVE_year[month(ymd(IMPROVE_year$Date)) %in% months, ]
  
  ## --- merge IMPROVE and CSN data ---
  # check common codes
  sites_CSN <- as.character(unique(CSN_y_m$SiteCode))
  sites_IMPROVE <- unique(IMPROVE_y_m$SiteCode)
  # check common species
  colnames(CSN_y_m)[48] <- "PM2.5"
  colnames(CSN_y_m)[47] <- "Na"
  colnames(CSN_y_m)[46] <- "K"
  species_CSN <- colnames(CSN_y_m)
  species_IMPROVE <- colnames(IMPROVE_y_m)
  common_species <- intersect(species_CSN, species_IMPROVE)
  
  merged_species <- rbind(CSN_y_m[, common_species],
                          IMPROVE_y_m[,common_species])
  merged_species$monitor <- c(rep('CSN',dim(CSN_y_m)[1]), 
                              rep('IMPROVE',dim(IMPROVE_y_m)[1]))
  merged_species = as.data.frame(merged_species)
  
  par(mfrow=c(3,3))
  for (i in 5:40){
    hist(merged_species[,i], nclass=100, 
         xlab=" ",main=colnames(merged_species)[i])}
  
  # log-trasformation
  merged_species_log = merged_species
  merged_species_log[,5:40] = log(merged_species[,5:40])
  par(mfrow=c(3,3))
  for (i in 5:40){
    hist(merged_species_log[,i], nclass=100, 
         xlab=" ",main=paste0(colnames(merged_species_log)[i], " - log"))}

  ## --- positions information ---
  merged_species_log<-merged_species_log[which(merged_species_log$SiteCode %in% 
                           as.character(IMPROVE_CSN_long_lat$SiteCode)),]
  merged_species_log$latitude <- sapply(merged_species_log$SiteCode, function(i) 
    IMPROVE_CSN_long_lat$Latitude[which(IMPROVE_CSN_long_lat$SiteCode== i)])
  merged_species_log$longitude <- sapply(merged_species_log$SiteCode, function(i) 
    IMPROVE_CSN_long_lat$Longitude[which(IMPROVE_CSN_long_lat$SiteCode== i)])
  merged_species_log$rural <- sapply(merged_species_log$SiteCode, function(i) 
    IMPROVE_CSN_long_lat$RuralUrban[which(IMPROVE_CSN_long_lat$SiteCode== i)])
  
  ## --- PM2.5 from wildfire smoke ---
  # Load full set of dates
  dates = unique(merged_species_log$Date)
  # Get full combination of grid cell-days
  # Warning: this may require a large amount of memory
  out = expand.grid(grid_id_10km = grid_10km$ID, date = dates)
  # Match smokePM predictions on smoke days to grid cell-days
  out = left_join(out, preds, by = c("grid_id_10km", "date"))
  # Predict 0 for remaining grid cell-days, which are non-smoke days
  out = mutate(out, smokePM_pred = replace_na(smokePM_pred, 0))
  
  #merging with monitoring data
  extract_coords<-sapply(grid_10km[[4]], function(x) unlist(x))
  grid_10km$longitude<-apply(extract_coords[1:4,],2,mean)
  grid_10km$latitude<-apply(extract_coords[6:9,],2,mean)
  
  # selection wildfire id
  merged_species_log$ID_wildfire<-rep(0)
  for(c in 1:(dim(merged_species_log)[1])){
    position<-which.min(abs(merged_species_log$latitude[c]-grid_10km$latitude+
                              merged_species_log$longitude[c]-grid_10km$longitude))
    merged_species_log$ID_wildfire[c]<-grid_10km$ID[position]
  }
  out_selected<-out[out$grid_id_10km %in% merged_species_log$ID_wildfire,]
  merged_species_log <- merge(merged_species_log, 
                              out_selected, 
                              by.x = c("Date", "ID_wildfire"), 
                              by.y = c("date", "grid_id_10km"),
                              all.x = TRUE)

  par(mfrow=c(1,1))
  hist(merged_species_log$smokePM_pred, nclass=100, xlab=" ", main="wildfire smoke")
  legend('topright', legend=c(paste0(sum(merged_species_log$smokePM_pred==0), ' units w/o wildfire'),
                              paste0(sum(merged_species_log$smokePM_pred>0), ' units w/ wildfire')))
  
  ## --- merge weather ---
  weather_2024$date <- as.Date(weather_2024$date, format="%Y-%m-%d %H:%M:%S")
  weather_2024 <- weather_2024[weather_2024$date %in% dates,]
  
  GEOINFO_ZCTA$id_ZCTA <-substr(GEOINFO_ZCTA$id_ZCTA, nchar(GEOINFO_ZCTA$id_ZCTA) - 4, nchar(GEOINFO_ZCTA$id_ZCTA))
  weather_2024 <- merge(weather_2024, GEOINFO_ZCTA, 
                     by.x = "zcta", by.y = "id_ZCTA")
  
  temp_data <- merged_species_log[,c(2,43,44)]
  temp_data <- unique(temp_data)
  temp_data <- temp_data %>%
    group_by(ID_wildfire) %>%
    summarise(latitude = mean(latitude),
              longitude = mean(longitude))
  temp_weather <- weather_2024[,c(1,13,14)]
  temp_weather <- unique(temp_weather)
  
  temp_data$zcta_useful<-rep(0)
  for(c in 1:(dim(temp_data)[1])){
    position<-which.min(abs(temp_data$latitude[c]-temp_weather$Latitude+
                              temp_data$longitude[c]-temp_weather$Longitude))
    temp_data$zcta_useful[c]<-temp_weather$zcta[position]
  }
  weather_2024 <- merge(weather_2024, temp_data[,c(1,4)], 
                     by.x = "zcta", 
                     by.y = "zcta_useful", 
                     all.x = TRUE)
  weather_2024 <- weather_2024 %>% 
    filter(!is.na(ID_wildfire))
 merged_species_log <- merge(merged_species_log,
                             weather_2024[,c(2:12,15)],
                             by.x = c("Date","ID_wildfire"),
                             by.y = c("date","ID_wildfire"),
                             all.x = TRUE)
                                
  ## --- merge census data ---
 ### sistemo
  census_data<-cbind(coords_6[,2:3],my_points[,2:13])
  census_data <- census_data[,-15]
  final_dataset <- merge(merged_species_log,census_data,
                         by = c('latitude','longitude'),
                         all.x = TRUE)
  
  final_dataset_temp <- unique(final_dataset)
  final_dataset_temp$unit_ID <- paste(final_dataset_temp$SiteCode, final_dataset_temp$Date)
  final_dataset_temp$month <- month(ymd(final_dataset_temp$Date))
  final_dataset_temp <- final_dataset_temp[, -c(5:7)]
  
  return(final_dataset_temp)
}
```

# Data analysis

```{r merging_data, eval=FALSE, message=TRUE, warning=FALSE}
dataset_2014_summer<-merge_data_days(year=2014, 
                                     months=c(7,8,9))
```

# Matching 1-to-1

For each month:

-   checking balance
-   visualization of control and treated groups geographically

**The threshould for wildfire smoke days changes for each month.** June and september is $0$, while for july and august is $5$. See histogram for wildfire smoke days distribution.

```{r matching, message=TRUE, warning=TRUE}

matching<-function(dataset, threshold){
  # preapre dataset
  dataset$treat <- 1*(dataset$smokePM_pred>threshold)
  dataset$monitor <- as.factor(dataset$monitor)
  dataset$rural <- as.factor(dataset$rural)
  dataset[,44:65]<-scale(dataset[,44:65])
  data_rnames <- row.names(dataset)
 
  print(table(dataset$treat))
  # match data using matchit
  m_temp <- matchit(treat ~ monitor + rural + sph + vpd + tmmn + tmmx + pr + 
                      rmin + rmax + srad + vs + th + B00001_001 + B00002_001 + 
                      B01001_001 + B02001_002 + B02001_003 + B02001_005 + 
                      B02001_007 + B01003_001 + B02001_001 + B19001_001 + 
                      B20004_001 + C17002_001, data = dataset, 
                    method = "nearest", distance = "glm", replace = FALSE)
  matched_data <- match.data(m_temp, data = dataset)
  matched_rnames <- row.names(matched_data)
  # make sure matched row names are all in data_temp row names
  all(matched_rnames %in% data_rnames)

  data_love <- matched_data[,c(68,44:65)]
  w_out <- weightit(treat ~ ., data = data_love, estimand = "ATE", method = "ps")
  #love.plot(bal.tab(w_out), binary = 'std', thresholds = c(m = .1))
  comparison_matching<-bal.tab(w_out)[[1]][,-(2)]
  comparison_matching$prob.1<-1*(abs(comparison_matching[,2])>0.1)
  comparison_matching$prob.1[comparison_matching$prob.1==1]<-'*'
  comparison_matching$prob.1[abs(comparison_matching[,2])>0.5]<-'**'
  print(comparison_matching)
  
  # get matched data
  match <- get_matches(m_temp)
  dataset_matched <- match[,c(4:71)]

  return(dataset_matched)
}


matched_summer14<-matching(dataset=dataset_2014_summer, threshold=0)
```

```{r echo=FALSE}
load("~/Documents/GitHub/BayesCausalFactor/Data/results_application_00.RData")
```

```{r eval=TRUE, echo=TRUE}
elements_matched <- colnames(matched_summer14)[5:40]
elements_paper <- c( "Mg", "Ca","Sr","Na","Rb","K","Cr","Ni","V","Cu","Fe",
                     "Ti","Zn","Mn","As","Si","Pb","Al","Se","NO3","SO4","S",
                     "P","Cl","Br","EC","OC")
names_chemicals<-c("Magnesium", "Calcium", "Strontium", "Sodium", "Rubidium",
                   "Potassium", "Chromium", "Nickel", "Vanadium", "Copper",
                   "Iron", "Titanium", "Zinc", "Manganese", "Arsenic", 
                   "Silicon", "Lead", "Aluminum", "Selenium", "Nitrate",
                   "Sulfate", "Sulfur", "Phosphorus", "Chlorine", "Bromine", 
                   "Elemental Carbon", "Organic Carbon")
matrix_elements_ordered <- sapply(elements_paper, function(i) which(elements_matched==i))
matrix_elements_ordered <- unlist(matrix_elements_ordered)+4

def_dataset <- cbind(matched_summer14[,c(66,3:4)],
                     matched_summer14[,matrix_elements_ordered],
                     matched_summer14[,c(1:2,41:42,44:65,67,43,68)])

chem_cell <-c(4:30)

means_chemical <- cbind(apply(def_dataset[def_dataset$smokePM_pred==0,chem_cell],2,mean),
      apply(def_dataset[def_dataset$smokePM_pred>0,chem_cell],2,mean))

means_chemical_july <- cbind(apply(def_dataset[def_dataset$smokePM_pred==0 &
                                              def_dataset$month == 7,chem_cell],2,mean),
      apply(def_dataset[def_dataset$smokePM_pred>0 & def_dataset$month == 7,chem_cell],2,mean))
means_chemical_aug <- cbind(apply(def_dataset[def_dataset$smokePM_pred==0 &
                                             def_dataset$month == 8,chem_cell],2,mean),
      apply(def_dataset[def_dataset$smokePM_pred>0 & def_dataset$month == 8,chem_cell],2,mean))
means_chemical_sept <- cbind(apply(def_dataset[def_dataset$smokePM_pred==0 &
                                              def_dataset$month == 9,chem_cell],2,mean),
      apply(def_dataset[def_dataset$smokePM_pred>0 & def_dataset$month == 9,chem_cell],2,mean))
table_months<-round(cbind(means_chemical[,2]-means_chemical[,1],
                             means_chemical_july[,2]-means_chemical_july[,1],
                             means_chemical_aug[,2]-means_chemical_aug[,1],
                             means_chemical_sept[,2]-means_chemical_sept[,1]),2)
colnames(table_months)<-c("summer","july","aug","sept")
table_months
```

# Analysis correlation

```{r correlation}

corr_plot_function <- function(dataset, threshold){
  par(mfrow = c(1, 2))
  corrplot(cor(dataset[dataset$treat==0,chem_cell]), 
           method = "color", type ="upper", tl.col = "black", tl.srt = 55, 
           tl.cex = 0.5)
  title(main = paste0("observed Y(0) - thr ", threshold))
  corrplot(cor(dataset[dataset$treat==1,chem_cell]), 
           method = "color", type = "upper", tl.col = "black", tl.srt = 55, 
           tl.cex = 0.5)
   title(main = paste0("observed Y(1) - thr ", threshold))
}

corr_plot_function(dataset=def_dataset, threshold=0)

```

# Model estimation

### Our proposed model

```{r model, eval=FALSE, message=TRUE, warning=TRUE}

select_factors<-function(dataset){
  fa.eigen_0 <- eigen(cor(data.matrix(dataset[dataset$treat==0,chem_cell])))
  fa.eigen_1 <- eigen(cor(data.matrix(dataset[dataset$treat==1,chem_cell])))
  par(mfrow=c(1,2))
  plot(fa.eigen_0$values, type='b', ylab='Eigenvalues', xlab='Factor')
  #abline(h=0.1, col="gray")
  plot(fa.eigen_1$values, type='b', ylab='Eigenvalues', xlab='Factor')
  #abline(h=0.1, col="gray")
}

estimation_model<-function(dataset, factors=c(5,5), y_list){
  
  X_0 <- dataset[dataset$treat==0,31:57]
  X_0$monitor <- 1*(X_0$monitor=="CSN")
  X_0$rural <- 1*(X_0$rural=="Mix") + 2*(X_0$rural=="Urban")
  X_0$aug <- 1*(X_0$month==8)
  X_0$sept <- 1*(X_0$month==9)
  X_0 <- X_0[,-27]
  X_0[,c(1:2,5:26)] <- scale(X_0[,c(1:2,5:26)])
  
  X_1 <- dataset[dataset$treat==1,31:57]
  X_1$monitor <- 1*(X_1$monitor=="CSN")
  X_1$rural <- 1*(X_1$rural=="Mix") + 2*(X_1$rural=="Urban")
  X_1$aug <- 1*(X_1$month==8)
  X_1$sept <- 1*(X_1$month==9)
  X_1 <- X_1[,-27]
  X_1[,c(1:2,5:26)] <- scale(X_1[,c(1:2,5:26)])
  
  Y_0 <- data.matrix(dataset[dataset$treat==0,y_list])
  Y_1 <- data.matrix(dataset[dataset$treat==1,y_list])
  
  st_causalFA <- causal_rfm_stand_mixfree_reg(Y_t=list(Y_0,Y_1), 
                                               j_t=factors,
                                               X_reg = list(rbind(1,t(X_0)),
                                                            rbind(1,t(X_1))), 
                                               X_weight =list(rbind(1,t(X_0[,-c(1:2)])),
                                                              rbind(1,t(X_1[,-c(1:2)]))), 
                                               R_cluster=10,
                                               outputlevel = 2,
                                               nrun = 8000, burn = 6500,
                                               nprint = 500)
  Y_1_est<-matrix(0,dim(dataset)[1],dim(Y_0)[2])
  Y_0_est<-matrix(0,dim(dataset)[1],dim(Y_0)[2])
  Y_1_est[dataset$treat==0,]<-st_causalFA$Y_mis_lt[[1]]
  Y_1_est[dataset$treat==1,]<-st_causalFA$Y_obs_lt[[2]]
  Y_0_est[dataset$treat==0,]<-st_causalFA$Y_obs_lt[[1]]
  Y_0_est[dataset$treat==1,]<-st_causalFA$Y_mis_lt[[2]]
  
  CE_across <- apply(st_causalFA$Y_obs_all[[2]]-st_causalFA$Y_mis_all[[2]],2:3,mean)/2 +
    apply(st_causalFA$Y_mis_all[[1]]-st_causalFA$Y_obs_all[[1]],2:3,mean)/2
  CE_PERC <- CE_across/abs(apply(st_causalFA$Y_obs_all[[2]],2:3,mean)/2 +
    apply(st_causalFA$Y_obs_all[[1]],2:3,mean)/2)*100
  
  RR_across <- apply(st_causalFA$Y_obs_all[[2]]/st_causalFA$Y_mis_all[[2]],2:3,mean)/2 +
    apply(st_causalFA$Y_mis_all[[1]]/st_causalFA$Y_obs_all[[1]],2:3,mean)/2
    
  return(list(Y_1_est=Y_1_est,Y_0_est=Y_0_est, 
              CE_across=CE_across, CE_PERC=CE_PERC,
              RR_across=RR_across, sigma=st_causalFA$SigmaLambda))
}

select_factors(dataset = def_dataset)


model_00_paper<-estimation_model(dataset = def_dataset, 
                                factors=c(10,10), 
                                y_list=chem_cell)
```

### Standard Factor Model

```{r fa_model, eval=FALSE, message=TRUE, warning=TRUE}

estimation_standard_FactorModel<-function(dataset, factors=c(5,5), y_list){
  
  X_0 <- dataset[dataset$treat==0,31:57]
  X_0$monitor <- 1*(X_0$monitor=="CSN")
  X_0$rural <- 1*(X_0$rural=="Mix") + 2*(X_0$rural=="Urban")
  X_0$aug <- 1*(X_0$month==8)
  X_0$sept <- 1*(X_0$month==9)
  X_0 <- X_0[,-27]
  X_0[,c(1:2,5:26)] <- scale(X_0[,c(1:2,5:26)])
  
  X_1 <- dataset[dataset$treat==1,31:57]
  X_1$monitor <- 1*(X_1$monitor=="CSN")
  X_1$rural <- 1*(X_1$rural=="Mix") + 2*(X_1$rural=="Urban")
  X_1$aug <- 1*(X_1$month==8)
  X_1$sept <- 1*(X_1$month==9)
  X_1 <- X_1[,-27]
  X_1[,c(1:2,5:26)] <- scale(X_1[,c(1:2,5:26)])
  
  Y_0 <- data.matrix(dataset[dataset$treat==0,y_list])
  Y_1 <- data.matrix(dataset[dataset$treat==1,y_list])
  
  st_FA <- causal_fa_Lt_X(Y_t=list(Y_0,Y_1), 
                          j_t=factors,
                          X_t = list(rbind(1,t(X_0)),rbind(1,t(X_1))),
                          outputlevel = 2,
                          nrun = 8000, burn = 6500,
                          nprint = 500)
  Y_1_est<-matrix(0,dim(dataset)[1],dim(Y_0)[2])
  Y_0_est<-matrix(0,dim(dataset)[1],dim(Y_0)[2])
  Y_1_est[dataset$treat==0,]<-st_FA$Y_mis_lt[[1]]
  Y_1_est[dataset$treat==1,]<-st_FA$Y_obs_lt[[2]]
  Y_0_est[dataset$treat==0,]<-st_FA$Y_obs_lt[[1]]
  Y_0_est[dataset$treat==1,]<-st_FA$Y_mis_lt[[2]]
  
  CE_across <- apply(st_FA$Y_obs_all[[2]]-st_FA$Y_mis_all[[2]],2:3,mean)/2 +
    apply(st_FA$Y_mis_all[[1]]-st_FA$Y_obs_all[[1]],2:3,mean)/2
    
  return(list(Y_1_est=Y_1_est,Y_0_est=Y_0_est, 
              CE_across=CE_across))
}

stand_FM_00<-estimation_standard_FactorModel(dataset = def_dataset, 
                                factors=c(10,10), 
                                y_list=chem_cell)
```

### BART

```{r bart, eval=FALSE, message=TRUE, warning=TRUE}
bart_estimation<-function(Y_t, X_t, n_t){
  set.seed(1)
  
  # ------   prearing variables   ------
  T_level=c(rep(0, n_t[1]),rep(1, n_t[2]))    # treatment
  X=rbind(t(X_t[[1]]), t(X_t[[2]]) )          # covariates-confounders
  Y_obs=rbind(Y_t[[1]], Y_t[[2]])             # observed outcome
  dim_Y = dim(Y_obs)[2]
  
  # ------   BART estimation   ------
  extract_bart_results<-function(each_Y){
    bart_fit <- bartCause::bartc(as.matrix(each_Y),as.matrix(T_level), as.matrix(X),
                                 n.samples = 1000, n.burn = 1000)

     Y_obs_chain = bart_fit$mu.hat.obs[1,,]
     Y_cf_chain = bart_fit$mu.hat.cf[1,,]
     
     tau <- cbind(Y_cf_chain[,T_level==0] - Y_obs_chain[,T_level==0],
                  Y_obs_chain[,T_level==1] - Y_cf_chain[,T_level==1])
     tau <- apply(tau,1,mean)
     
     return(list(tau=tau))

  }
  # estimation
  bart_fit <- lapply(1:dim_Y, function(y) extract_bart_results(Y_obs[,y]))
  
  return(bart_fit)
}
parallel_funct_bart<-function(dataset, y_list){
  X_0 <- dataset[dataset$treat==0,31:57]
  X_0$monitor <- 1*(X_0$monitor=="CSN")
  X_0$rural <- 1*(X_0$rural=="Mix") + 2*(X_0$rural=="Urban")
  X_0$aug <- 1*(X_0$month==8)
  X_0$sept <- 1*(X_0$month==9)
  X_0 <- X_0[,-27]
  X_0[,c(1:2,5:26)] <- scale(X_0[,c(1:2,5:26)])
  
  X_1 <- dataset[dataset$treat==1,31:57]
  X_1$monitor <- 1*(X_1$monitor=="CSN")
  X_1$rural <- 1*(X_1$rural=="Mix") + 2*(X_1$rural=="Urban")
  X_1$aug <- 1*(X_1$month==8)
  X_1$sept <- 1*(X_1$month==9)
  X_1 <- X_1[,-27]
  X_1[,c(1:2,5:26)] <- scale(X_1[,c(1:2,5:26)])
  
  Y_0 <- data.matrix(dataset[dataset$treat==0,y_list])
  Y_1 <- data.matrix(dataset[dataset$treat==1,y_list])
  
  bart_model <- bart_estimation(Y_t = list(Y_0,Y_1), 
                         X_t = list(t(X_0),t(X_1)), 
                         n_t = c(sum(dataset$treat==0),sum(dataset$treat==1)))
  
  tau_all<-sapply(1:27, function(x) bart_model[[x]]$tau)
  return(tau_all)
}

bart_00 <- parallel_funct_bart(dataset = def_dataset, 
                               y_list=chem_cell)
```

### BCF

```{r bcf, eval=FALSE, message=TRUE, warning=TRUE}
BCF_estimation<-function(Y_t, X_t, n_t){
  set.seed(1)
  # ------   preparing variables   ------
  n_t = c(dim(X_t[[1]])[2],dim(X_t[[2]])[2])
  T_level=c(rep(0, n_t[1]),rep(1, n_t[2]))    # treatment
  X=rbind(t(X_t[[1]]), t(X_t[[2]]) )          # covariates-confounders
  Y_obs=rbind(Y_t[[1]], Y_t[[2]])             # observed outcome
  dim_Y = dim(Y_obs)[2]
  
  # ------   BCF estimation   ------
  
  extract_bcf_results<-function(each_Y){
    #propensity score
    p.score <- glm(T_level ~ X,
                   family = binomial,
                   data = as.data.frame(cbind(T_level, X)))
    pihat <- predict(p.score, as.data.frame(X))
    
    # estimation
    bcf_fit <- bcf(y=each_Y, z=T_level, x_control=as.matrix(X), pihat=pihat, 
                   nburn = 1000, nsim = 1000)
    
    return(tau=rowMeans(bcf_fit$tau))
  }
   
  # estimation
  bcf_fit_all <- sapply(1:dim_Y, function(y) extract_bcf_results(each_Y = Y_obs[,y]))
  
  return(list(bcf_fit_all))
}
  
parallel_funct_bcf<-function(dataset, threshold=0, y_list){
  
  X_0 <- dataset[dataset$treat==0,31:57]
  X_0$monitor <- 1*(X_0$monitor=="CSN")
  X_0$rural <- 1*(X_0$rural=="Mix") + 2*(X_0$rural=="Urban")
  X_0$aug <- 1*(X_0$month==8)
  X_0$sept <- 1*(X_0$month==9)
  X_0 <- X_0[,-27]
  X_0[,c(1:2,5:26)] <- scale(X_0[,c(1:2,5:26)])
  
  X_1 <- dataset[dataset$treat==1,31:57]
  X_1$monitor <- 1*(X_1$monitor=="CSN")
  X_1$rural <- 1*(X_1$rural=="Mix") + 2*(X_1$rural=="Urban")
  X_1$aug <- 1*(X_1$month==8)
  X_1$sept <- 1*(X_1$month==9)
  X_1 <- X_1[,-27]
  X_1[,c(1:2,5:26)] <- scale(X_1[,c(1:2,5:26)])
  
  Y_0 <- data.matrix(dataset[dataset$treat==0,y_list])
  Y_1 <- data.matrix(dataset[dataset$treat==1,y_list])
  
  bcf_model <- BCF_estimation(Y_t = list(Y_0,Y_1), 
                         X_t = list(t(X_0),t(X_1)), 
                         n_t = c(sum(dataset$treat==0),sum(dataset$treat==1)))
  
  #tau_all<-sapply(1:26, function(x) bcf_model[[x]]$tau)
  return(bcf_model)
}

bcf_00 <- parallel_funct_bcf(dataset = def_dataset, 
                             threshold=0,
                             y_list=chem_cell)
```

### Results: Causal effects

Comparison of the causal effect $E[Y_k(1)-Y_k(0)]$ for $k$ indicate the chemical component:

-   our proposed model: the boxplots indicate the posterior distribution
-   BART: the gray star and rhombus indicate the posterior mean and median

```{r plot_results_ce_function, echo=FALSE}

plot_aspaper_vertical<-function(ce_ourmodel,bart_results,bcf_results,month){
  
  mean_our=apply(ce_ourmodel[, 1001:1500],1,median)
CI_our=apply(ce_ourmodel[, 1001:1500],1, quantile, probs=c(0.05,0.95))
CI_bart=apply(bart_results,2, quantile, probs=c(0.05,0.95))
CI_bcf=apply(bcf_results,2, quantile, probs=c(0.05,0.95))
colors <- colorRampPalette(brewer.pal(11, "Spectral"))(26)

colors_paper <- c(rep("#694573",3), rep("#8E414E",3),
                  rep("#F99D5B",8), rep("#FDCE57",2),
                  rep("#BDDEF2",2), rep("#86BF6B",5),
                  rep("#A86A8C",2), rep("#72A3A8",2))

plot(mean_our,27:1, pch=16, col=colors_paper,
     xlim=c(min(min(CI_our),0), min(max(CI_our),120)),
     ylab='', xlab=' ', main=month,
     yaxt = "n",bty = "n", cex=1)
segments(CI_our[1,], 27:1, CI_our[2,],27:1, col=colors_paper, lwd = 2)
points( apply(bart_results, 2, mean),27:1+0.2, col="black", cex=0.5)
points( apply(bcf_results, 2, mean),27:1+0.4, col="red", cex=0.5)
segments(CI_bart[1,], 27:1+0.2, CI_bart[2,],27:1+0.2, col="black")
segments(CI_bcf[1,], 27:1+0.4, CI_bcf[2,],27:1+0.4, col="red")
text(par("usr")[1],27:1, cex=0.7,
     names_chemicals, srt = 0, xpd = TRUE, adj = 1)
abline(v=0, col="gray")
}

plot_aspaper_nobart<-function(ce_ourmodel,month, gray_line, lims){
  
  mean_our=apply(ce_ourmodel,1,median)
CI_our=apply(ce_ourmodel,1, quantile, probs=c(0.05,0.95))

colors_paper <- c(rep("#694573",3), rep("#8E414E",3),
                  rep("#F99D5B",8), rep("#FDCE57",2),
                  rep("#BDDEF2",2), rep("#86BF6B",5),
                  rep("#A86A8C",2), rep("#72A3A8",2))

plot(mean_our,27:1, pch=16, col=colors_paper,
     xlim=c(min(min(CI_our),lims[1]), min(max(CI_our),lims[2])),
     ylab='', xlab='', main=month,
     yaxt = "n",bty = "n", cex=1)
segments(CI_our[1,], 27:1, CI_our[2,],27:1, col=colors_paper, lwd = 2)
abline(v=gray_line, col="gray")
text(par("usr")[1],27:1, cex=0.7,
     names_chemicals, srt = 0, xpd = TRUE, adj = 1)
}

```

```{r plot_results_ce}
par(mfrow = c(1, 2))
plot_aspaper_vertical(ce_ourmodel=model_00_paper$CE_across,
                      bart_results=bart_00,
                      bcf_results=bcf_00[[1]],
                      month='Y(1)-Y(0)')
plot(0:10,0:10,type = 'n', yaxt = "n",bty = "n",xaxt = "n",ylab='',xlab='')
op <- par(cex = 0.5)
legend(0,5, c("Our model (CRFM):","pos. median","CI 95%"," ","BART:",
              "pos. median","CI 95%"," ","BCF:","pos. median","CI 95%"),
       pch=c(NA,19,NA,NA,NA,19,NA,NA,NA,19,NA), 
       col=c(NA,"gray","gray",NA,NA,1,1,NA,NA,2,2), 
       lty=c(NA,NA,1,NA,NA,NA,1,NA,NA,NA,1), bty = "n")

par(mfrow = c(1, 1))
plot_aspaper_nobart(ce_ourmodel=model_00_paper$CE_across,
                     lims = c(0,50),
                      month='Y(1)-Y(0)',
                    gray_line=0)

par(mfrow = c(1, 1))
plot_aspaper_nobart(ce_ourmodel=model_00_paper$CE_PERC,
                     lims = c(-10,150),
                      month='[Y(1)-Y(0)]/|Y(0)| %',
                    gray_line=0)

par(mfrow = c(1, 1))
plot_aspaper_nobart(ce_ourmodel=abs(model_MM0_paper$CE_PERC),
                     lims = c(-1,95),
                      month='wrong estimation !',
                    gray_line=0)
```

```{r factors_plots}

library(plot.matrix)
library(RColorBrewer)

selection_factors <- function(sigma_matrix,treat_level){
  
  eigenPhi <- eigen(sigma_matrix)
  d_value <- eigenPhi$values 
  choiceK <- d_value / sum(d_value)

  print(round(choiceK,3))
  
  k <- length(which(choiceK>0.1))
  val_matrix <- diag(sqrt(d_value))
  load <- eigenPhi$vec %*% val_matrix
  loadK <- load[,1:k]
  rownames(loadK) <- rep(" ",27)
  
  par(mfrow=c(1,1), mar=c(5.1, 4.1,4.1,4.1))
  breaks=c(-0.7,-0.5,-0.3,-0.1,-0.05,0.05,0.1,0.3,0.5,0.7)
  cols <- brewer.pal(9, "RdBu")
  plot(-loadK, 
       main=treat_level, breaks=breaks,
       xlab=" ", ylab=" ", yaxt = "n", bty = "n",
       border=NA, digits=2, 
       text.cell=list(cex=0.45),
       col=cols,
       key=list(side=4,  font=1, cex.axis=0.75))
  axis(2, at = 1:27, labels = names_chemicals[27:1], las = 2, cex.axis = 0.5)
}

selection_factors_varimax <- function(sigma_matrix,treat_level, th_var){
  
  eigenPhi <- eigen(sigma_matrix)
  d_value <- eigenPhi$values 
  choiceK <- d_value / sum(d_value)

  round(choiceK,3)
  
  k <- length(which(choiceK>th_var))
  loadK <- varimax(eigenPhi$vectors[,1:k])$loadings
  prova<- loadK[1:27,]
  rownames(prova) <- rep(" ",27)
  def_matrix <- sapply(1:k, function(i) sign(prova[which.max(abs(prova[,i])),i])*prova[,i])
  
  par(mfrow=c(1,1), mar=c(5.1, 4.1,4.1,4.1))
  breaks=c(-0.9,-0.6,-0.45,-0.3,-0.2,-0.09,0.09,0.2,0.3,0.45,0.6,0.9)
  cols <- brewer.pal(11, "RdBu")
  plot(def_matrix, 
       main=treat_level, breaks=breaks,
       xlab=" ", ylab=" ", yaxt = "n", bty = "n",
       border=NA, digits=2, 
       text.cell=list(cex=0.45),
       col=cols,
       key=list(side=4,  font=1, cex.axis=0.75))
  axis(2, at = 1:27, labels = names_chemicals[27:1], las = 2, cex.axis = 0.5)
}

selection_factors_varimax_op2 <- function(sigma_matrix,treat_level, th_var){
  
  eigenPhi <- eigen(sigma_matrix)
  d_value <- eigenPhi$values 
  choiceK <- d_value / sum(d_value)

  round(choiceK,3)
  
  k <- length(which(choiceK>th_var))
  loadK <- varimax(eigenPhi$vectors[,1:k])$loadings
  rownames(loadK) <- names_chemicals
  
  par(mfrow=c(1,1), mar=c(5.1, 4.1,4.1,4.1))
  breaks=c(-0.9,-0.6,-0.45,-0.3,-0.2,-0.09,0.09,0.2,0.3,0.45,0.6,0.9)
  cols <- brewer.pal(11, "RdBu")
  plot(loadK, 
       main=treat_level, breaks=breaks,
       xlab=" ", ylab=" ", bty = "n",
       border=NA, digits=2, las=2, , cex.axis=0.5,
       text.cell=list(cex=0.45),
       col=cols)
}

selection_factors(sigma_matrix = model_00_paper$sigma[[1]], 
                  treat_level="w/o wildfire")
selection_factors(sigma_matrix = model_00_paper$sigma[[2]], 
                  treat_level="w/ wildfire")

selection_factors_varimax(sigma_matrix = model_00_paper$sigma[[1]], 
                  treat_level="w/o wildfire",
                  th_var=0.1)
selection_factors_varimax(sigma_matrix = model_00_paper$sigma[[2]], 
                  treat_level="w/ wildfire",
                  th_var=0.1)
selection_factors_varimax(sigma_matrix = model_00_paper$sigma[[1]], 
                  treat_level="w/o wildfire",
                  th_var=0.05)
selection_factors_varimax(sigma_matrix = model_00_paper$sigma[[2]], 
                  treat_level="w/ wildfire",
                  th_var=0.05)

selection_factors_varimax_op2(sigma_matrix = model_00_paper$sigma[[1]], 
                  treat_level="w/o wildfire",
                  th_var=0.1)
selection_factors_varimax_op2(sigma_matrix = model_00_paper$sigma[[2]], 
                  treat_level="w/ wildfire",
                  th_var=0.1)

```
